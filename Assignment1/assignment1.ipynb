{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOSTAT 826 - Assignment 1\n",
    "Mortality prediction in MIMIC-IV using ICD-10 diagnosis and procedure categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1916083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "repo_root = Path.cwd()\n",
    "if not (repo_root / 'utils').exists():\n",
    "    repo_root = repo_root.parent\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from utils.data import assemble_dataset, load_code_descriptions\n",
    "from utils.evaluation import (\n",
    "    TemperatureScaler,\n",
    "    bootstrap_metric_ci,\n",
    "    calibration_curve_quantile,\n",
    "    calibration_slope_intercept,\n",
    "    compute_basic_metrics,\n",
    "    sigmoid,\n",
    "    specificity_at_sensitivity,\n",
    ")\n",
    "from utils.training import (\n",
    "    LogisticRegressionModel,\n",
    "    MLPRiskModel,\n",
    "    build_dataloader,\n",
    "    coefficient_table,\n",
    "    extract_linear_weights,\n",
    "    predict_logits,\n",
    "    set_seed,\n",
    "    train_lr_sweep_with_models,\n",
    "    train_model,\n",
    "    tune_l1_strength,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a92fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(826)\n",
    "data_dir = Path('/home/rl/mimic-iv-3.1/mimic-iv-3.1/hosp')\n",
    "bundle = assemble_dataset(data_dir, min_count=10, seed=826)\n",
    "desc = load_code_descriptions(data_dir)\n",
    "\n",
    "X = bundle.X\n",
    "y = bundle.y.astype(np.float32)\n",
    "splits = bundle.splits\n",
    "feature_names = bundle.feature_names\n",
    "\n",
    "X_train, y_train = X[splits['train']], y[splits['train']]\n",
    "X_val, y_val = X[splits['val']], y[splits['val']]\n",
    "X_cal, y_cal = X[splits['cal']], y[splits['cal']]\n",
    "X_test, y_test = X[splits['test']], y[splits['test']]\n",
    "\n",
    "print('n_admissions:', X.shape[0])\n",
    "print('n_features:', X.shape[1])\n",
    "print('mortality_rate:', float(y.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f85c7c",
   "metadata": {},
   "source": [
    "### Feature scaling for MLP\n",
    "Use train-set standardization (no centering for sparse matrix). We keep raw binary features for LR interpretability, and use scaled features for MLP fitting stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_cal_scaled = scaler.transform(X_cal)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993fdd50",
   "metadata": {},
   "source": [
    "## Part 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ae53e",
   "metadata": {},
   "source": [
    "### LR sweep means trying multiple learning rates\n",
    "Here we train the same logistic regression with different learning rates and compare optimization behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f93b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = build_dataloader(X_train, y_train, batch_size=200, shuffle=True)\n",
    "val_loader = build_dataloader(X_val, y_val, batch_size=200, shuffle=False)\n",
    "cal_loader = build_dataloader(X_cal, y_cal, batch_size=200, shuffle=False)\n",
    "test_loader = build_dataloader(X_test, y_test, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc507e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "lr_sweep = train_lr_sweep_with_models(\n",
    "    lambda: LogisticRegressionModel(X.shape[1]),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    lrs,\n",
    "    max_epochs=40,\n",
    "    patience=6,\n",
    ")\n",
    "\n",
    "lr_summary = []\n",
    "for lr, trained in lr_sweep.items():\n",
    "    lr_summary.append({\n",
    "        'lr': lr,\n",
    "        'epochs': len(trained.result.history['epoch_train_loss']),\n",
    "        'best_epoch': trained.result.best_epoch,\n",
    "        'best_val_loss': min(trained.result.history['val_loss']),\n",
    "    })\n",
    "lr_summary_df = pd.DataFrame(lr_summary).sort_values('lr').reset_index(drop=True)\n",
    "lr_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ec9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "for lr, trained in lr_sweep.items():\n",
    "    plt.plot(trained.result.history['batch_train_loss'], label=f'lr={lr:g}', alpha=0.9)\n",
    "plt.xlabel('Mini-batch step')\n",
    "plt.ylabel('Mini-batch BCE loss')\n",
    "plt.title('Logistic regression mini-batch loss by learning rate')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8437c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = float(lr_summary_df.sort_values('best_val_loss').iloc[0]['lr'])\n",
    "lr_best_model = lr_sweep[best_lr].model\n",
    "lr_best_weights = extract_linear_weights(lr_best_model)\n",
    "lr_top20, lr_bottom20 = coefficient_table(lr_best_weights, feature_names, desc, top_k=20)\n",
    "\n",
    "print(f'Best LR by validation loss: {best_lr:g}')\n",
    "print('Top 20 categories increasing log-odds')\n",
    "display(lr_top20)\n",
    "print('Top 20 categories decreasing log-odds')\n",
    "display(lr_bottom20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b95b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_grid = [0.0, 1e-6, 3e-6, 1e-5, 3e-5, 1e-4, 3e-4, 1e-3]\n",
    "chosen_l1, l1_trained, l1_table = tune_l1_strength(\n",
    "    lambda: LogisticRegressionModel(X.shape[1]),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    l1_grid,\n",
    "    target_sparsity=0.85,\n",
    "    lr=best_lr,\n",
    "    max_epochs=40,\n",
    "    patience=6,\n",
    ")\n",
    "\n",
    "print('Chosen L1 lambda:', chosen_l1)\n",
    "l1_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_weights = extract_linear_weights(l1_trained.model)\n",
    "l1_top20, l1_bottom20 = coefficient_table(l1_weights, feature_names, desc, top_k=20)\n",
    "\n",
    "print('L1 model top 20 categories increasing log-odds')\n",
    "display(l1_top20)\n",
    "print('L1 model top 20 categories decreasing log-odds')\n",
    "display(l1_bottom20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addee622",
   "metadata": {},
   "source": [
    "## Part 3 - Neural Network Risk Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b873183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn_experiments(X_train_local, y_train_local, X_val_local, y_val_local, hidden_sizes):\n",
    "    train_local = build_dataloader(X_train_local, y_train_local, batch_size=200, shuffle=True)\n",
    "    val_local = build_dataloader(X_val_local, y_val_local, batch_size=200, shuffle=False)\n",
    "    results = {}\n",
    "    input_dim = X_train_local.shape[1]\n",
    "    for hidden_dim in hidden_sizes:\n",
    "        model = MLPRiskModel(input_dim, hidden_dim=hidden_dim)\n",
    "        result = train_model(\n",
    "            model,\n",
    "            train_local,\n",
    "            val_local,\n",
    "            lr=1e-3,\n",
    "            max_epochs=35,\n",
    "            patience=6,\n",
    "        )\n",
    "        results[hidden_dim] = {'model': model, 'result': result}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d743ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [100, 1000, 5000]\n",
    "nn_full = run_nn_experiments(X_train_scaled, y_train, X_val_scaled, y_val, hidden_sizes)\n",
    "\n",
    "nn_full_summary = []\n",
    "for h, item in nn_full.items():\n",
    "    nn_full_summary.append({\n",
    "        'hidden_size': h,\n",
    "        'epochs': len(item['result'].history['epoch_train_loss']),\n",
    "        'best_epoch': item['result'].best_epoch,\n",
    "        'best_val_loss': min(item['result'].history['val_loss']),\n",
    "    })\n",
    "nn_full_summary_df = pd.DataFrame(nn_full_summary).sort_values('hidden_size').reset_index(drop=True)\n",
    "nn_full_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33876162",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4), sharey=True)\n",
    "for i, h in enumerate(hidden_sizes):\n",
    "    hist = nn_full[h]['result'].history\n",
    "    axes[i].plot(hist['epoch_train_loss'], label='train')\n",
    "    axes[i].plot(hist['val_loss'], label='val')\n",
    "    axes[i].set_title(f'Hidden={h}')\n",
    "    axes[i].set_xlabel('Epoch')\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Loss')\n",
    "        axes[i].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67551a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(826)\n",
    "downsample_n = max(1, len(y_train) // 10)\n",
    "down_idx = rng.choice(np.arange(len(y_train)), size=downsample_n, replace=False)\n",
    "X_train_down = X_train_scaled[down_idx]\n",
    "y_train_down = y_train[down_idx]\n",
    "\n",
    "nn_down = run_nn_experiments(X_train_down, y_train_down, X_val_scaled, y_val, hidden_sizes)\n",
    "\n",
    "nn_down_summary = []\n",
    "for h, item in nn_down.items():\n",
    "    nn_down_summary.append({\n",
    "        'hidden_size': h,\n",
    "        'epochs': len(item['result'].history['epoch_train_loss']),\n",
    "        'best_epoch': item['result'].best_epoch,\n",
    "        'best_val_loss': min(item['result'].history['val_loss']),\n",
    "    })\n",
    "nn_down_summary_df = pd.DataFrame(nn_down_summary).sort_values('hidden_size').reset_index(drop=True)\n",
    "nn_down_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4), sharey=True)\n",
    "for i, h in enumerate(hidden_sizes):\n",
    "    hist = nn_down[h]['result'].history\n",
    "    axes[i].plot(hist['epoch_train_loss'], label='train')\n",
    "    axes[i].plot(hist['val_loss'], label='val')\n",
    "    axes[i].set_title(f'Downsampled Hidden={h}')\n",
    "    axes[i].set_xlabel('Epoch')\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Loss')\n",
    "        axes[i].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e6bc0",
   "metadata": {},
   "source": [
    "## Part 4 - Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ea9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nn_hidden = int(nn_full_summary_df.sort_values('best_val_loss').iloc[0]['hidden_size'])\n",
    "nn_best_model = nn_full[best_nn_hidden]['model']\n",
    "\n",
    "lr_logits_cal = predict_logits(lr_best_model, cal_loader)\n",
    "lr_logits_test = predict_logits(lr_best_model, test_loader)\n",
    "nn_cal_loader = build_dataloader(X_cal_scaled, y_cal, batch_size=200, shuffle=False)\n",
    "nn_test_loader = build_dataloader(X_test_scaled, y_test, batch_size=200, shuffle=False)\n",
    "nn_logits_cal = predict_logits(nn_best_model, nn_cal_loader)\n",
    "nn_logits_test = predict_logits(nn_best_model, nn_test_loader)\n",
    "\n",
    "lr_scaler = TemperatureScaler()\n",
    "nn_scaler = TemperatureScaler()\n",
    "lr_temp = lr_scaler.fit(lr_logits_cal, y_cal)\n",
    "nn_temp = nn_scaler.fit(nn_logits_cal, y_cal)\n",
    "\n",
    "lr_prob_raw = sigmoid(lr_logits_test)\n",
    "lr_prob_cal = sigmoid(lr_logits_test / lr_temp)\n",
    "nn_prob_raw = sigmoid(nn_logits_test)\n",
    "nn_prob_cal = sigmoid(nn_logits_test / nn_temp)\n",
    "\n",
    "print('Best NN hidden size:', best_nn_hidden)\n",
    "print('Temperature LR:', lr_temp)\n",
    "print('Temperature NN:', nn_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_sens = [0.80, 0.85, 0.90]\n",
    "sens_rows = []\n",
    "for target in candidate_sens:\n",
    "    lr_sens, lr_spec, _ = specificity_at_sensitivity(y_test, lr_prob_cal, target)\n",
    "    nn_sens, nn_spec, _ = specificity_at_sensitivity(y_test, nn_prob_cal, target)\n",
    "    sens_rows.append({\n",
    "        'target_sensitivity': target,\n",
    "        'lr_specificity': lr_spec,\n",
    "        'nn_specificity': nn_spec,\n",
    "        'mean_specificity': (lr_spec + nn_spec) / 2.0,\n",
    "    })\n",
    "sens_df = pd.DataFrame(sens_rows).sort_values('mean_specificity', ascending=False).reset_index(drop=True)\n",
    "fixed_sensitivity = float(sens_df.iloc[0]['target_sensitivity'])\n",
    "print('Selected fixed sensitivity:', fixed_sensitivity)\n",
    "sens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_prob_cal)\n",
    "fpr_nn, tpr_nn, _ = roc_curve(y_test, nn_prob_cal)\n",
    "\n",
    "prec_lr, rec_lr, _ = precision_recall_curve(y_test, lr_prob_cal)\n",
    "prec_nn, rec_nn, _ = precision_recall_curve(y_test, nn_prob_cal)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'LR (AUROC={roc_auc_score(y_test, lr_prob_cal):.3f})')\n",
    "plt.plot(fpr_nn, tpr_nn, label=f'NN (AUROC={roc_auc_score(y_test, nn_prob_cal):.3f})')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(rec_lr, prec_lr, label=f'LR (AP={average_precision_score(y_test, lr_prob_cal):.3f})')\n",
    "plt.plot(rec_nn, prec_nn, label=f'NN (AP={average_precision_score(y_test, nn_prob_cal):.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_curve_raw = calibration_curve_quantile(y_test, lr_prob_raw, n_bins=15)\n",
    "lr_curve_cal = calibration_curve_quantile(y_test, lr_prob_cal, n_bins=15)\n",
    "nn_curve_raw = calibration_curve_quantile(y_test, nn_prob_raw, n_bins=15)\n",
    "nn_curve_cal = calibration_curve_quantile(y_test, nn_prob_cal, n_bins=15)\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.plot([0, 1], [0, 1], '--', color='black', label='Perfect calibration')\n",
    "plt.plot(lr_curve_raw['mean_pred'], lr_curve_raw['frac_pos'], 'o-', label='LR raw')\n",
    "plt.plot(lr_curve_cal['mean_pred'], lr_curve_cal['frac_pos'], 'o-', label='LR temp-scaled')\n",
    "plt.plot(nn_curve_raw['mean_pred'], nn_curve_raw['frac_pos'], 's-', label='NN raw')\n",
    "plt.plot(nn_curve_cal['mean_pred'], nn_curve_cal['frac_pos'], 's-', label='NN temp-scaled')\n",
    "plt.xlabel('Mean predicted probability (quantile bins)')\n",
    "plt.ylabel('Observed event rate')\n",
    "plt.title('Calibration Curves (Quantile Bins)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_auroc(y_true, y_prob):\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def metric_ap(y_true, y_prob):\n",
    "    return average_precision_score(y_true, y_prob)\n",
    "\n",
    "def metric_cal_slope(y_true, y_prob):\n",
    "    slope, _ = calibration_slope_intercept(y_true, y_prob)\n",
    "    return slope\n",
    "\n",
    "def metric_cal_intercept(y_true, y_prob):\n",
    "    _, intercept = calibration_slope_intercept(y_true, y_prob)\n",
    "    return intercept\n",
    "\n",
    "def metric_spec_at_fixed_sens(y_true, y_prob):\n",
    "    _, spec, _ = specificity_at_sensitivity(y_true, y_prob, fixed_sensitivity)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_bootstrap(model_name, y_true, y_prob, n_bootstrap=1000):\n",
    "    metrics = {\n",
    "        'AUROC': metric_auroc,\n",
    "        'AP': metric_ap,\n",
    "        'Calibration slope': metric_cal_slope,\n",
    "        'Calibration intercept': metric_cal_intercept,\n",
    "        f'Specificity @ sensitivity={fixed_sensitivity:.2f}': metric_spec_at_fixed_sens,\n",
    "    }\n",
    "    rows = []\n",
    "    for metric_name, fn in metrics.items():\n",
    "        point, (lo, hi), _ = bootstrap_metric_ci(\n",
    "            y_true,\n",
    "            y_prob,\n",
    "            fn,\n",
    "            n_bootstrap=n_bootstrap,\n",
    "            seed=826,\n",
    "        )\n",
    "        rows.append({\n",
    "            'model': model_name,\n",
    "            'metric': metric_name,\n",
    "            'estimate': point,\n",
    "            'ci_lower': lo,\n",
    "            'ci_upper': hi,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "result_lr = summarize_with_bootstrap('Logistic Regression', y_test, lr_prob_cal, n_bootstrap=1000)\n",
    "result_nn = summarize_with_bootstrap('Neural Network', y_test, nn_prob_cal, n_bootstrap=1000)\n",
    "results_df = pd.concat([result_lr, result_nn], ignore_index=True)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
